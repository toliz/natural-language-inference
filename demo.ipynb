{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d024a3",
   "metadata": {},
   "source": [
    "# Using NLI to Encode Sentences - Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa95a9",
   "metadata": {},
   "source": [
    "This notebook assumes that you've already followed the instructions on the `README.md` file. Hence, it is expected that you either have downloaded the pre-trained models and their results on SNLI & SentEval, or that you have trained your own models and tested them on SNLI & SentEval.\n",
    "\n",
    "In any case the folders `pretrained`, `senteval` and `tb_logs` should have some trained models and evaluations on SentEval and SNLI respectively.\n",
    "\n",
    "We start by importing the necessary libraries. The rest of the notebook is divided in two parts:\n",
    "- in the first part we evaluate all four pretrained models on SNLI & SentEval\n",
    "- in the second part we use some of the pretrained models to do inference on custom sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44667c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from data import SNLIDataModule\n",
    "from model import NLI\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "pd.options.display.precision = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89175dc3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b7c79",
   "metadata": {},
   "source": [
    "### Performance on SNLI\n",
    "\n",
    "Logs of the performance of all models on SNLI are stored in `tb_logs`. You can of course re-train all the models by uncommenting the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e94096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --encoder AWE\n",
    "# !python train.py --encoder LSTM\n",
    "# !python train.py --encoder BiLSTM\n",
    "# !python train.py --encoder BiLSTM-MaxPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32488dc",
   "metadata": {},
   "source": [
    "Let's see the Validation and Test accuracies our models achieved on SNLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1741f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNLI Val Acc</th>\n",
       "      <th>SNLI Test Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWE</th>\n",
       "      <td>65.57</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>80.40</td>\n",
       "      <td>80.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM</th>\n",
       "      <td>79.38</td>\n",
       "      <td>79.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM-MaxPool</th>\n",
       "      <td>83.61</td>\n",
       "      <td>80.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNLI Val Acc  SNLI Test Acc\n",
       "AWE                    65.57          65.73\n",
       "LSTM                   80.40          80.22\n",
       "BiLSTM                 79.38          79.44\n",
       "BiLSTM-MaxPool         83.61          80.56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_paths = {\n",
    "    'AWE': {\n",
    "        'validation': 'tb_logs/AWE/version_0/events.out.tfevents.1650439854.r30n1.lisa.surfsara.nl.12563.0', \n",
    "        'test': 'tb_logs/AWE/version_0/events.out.tfevents.1650441682.r30n1.lisa.surfsara.nl.12563.1',\n",
    "    },\n",
    "    'LSTM': {\n",
    "        'validation': 'tb_logs/LSTM/version_0/events.out.tfevents.1650440601.r30n1.lisa.surfsara.nl.14847.0',\n",
    "        'test': 'tb_logs/LSTM/version_0/events.out.tfevents.1650447205.r30n1.lisa.surfsara.nl.14847.1',\n",
    "    },\n",
    "    'BiLSTM': {\n",
    "        'validation': 'tb_logs/BiLSTM/version_0/events.out.tfevents.1650441709.r30n2.lisa.surfsara.nl.22540.0',\n",
    "        'test': 'tb_logs/BiLSTM/version_0/events.out.tfevents.1650450412.r30n2.lisa.surfsara.nl.22540.1',\n",
    "    },\n",
    "    'BiLSTM-MaxPool': {\n",
    "        'validation': 'tb_logs/BiLSTM-MaxPool/version_0/events.out.tfevents.1650447234.r30n6.lisa.surfsara.nl.25797.0',\n",
    "        'test': 'tb_logs/BiLSTM-MaxPool/version_0/events.out.tfevents.1650454387.r30n6.lisa.surfsara.nl.25797.1',\n",
    "    }\n",
    "}\n",
    "\n",
    "snli_results = defaultdict(list)\n",
    "\n",
    "# Iterate over all encoders\n",
    "for encoder in tb_paths.keys():\n",
    "    # Iterate over validation, test and possibly other splits\n",
    "    for split, path in tb_paths[encoder].items():\n",
    "        # Open the TensorBoard event file\n",
    "        ea = event_accumulator.EventAccumulator(\n",
    "            path,\n",
    "            size_guidance={event_accumulator.SCALARS: 0},\n",
    "        )\n",
    "        \n",
    "        _absorb_print = ea.Reload()\n",
    "        \n",
    "        # Get a list with the maximum accuracy (over epochs) in all splits\n",
    "        snli_results[encoder] += [100 * max([event.value for event in ea.Scalars(f'accuracy/{split}')])]\n",
    "\n",
    "# Convert the results to a dataframe    \n",
    "snli_results = pd.DataFrame(snli_results, index=['SNLI Val Acc', 'SNLI Test Acc']).T\n",
    "\n",
    "# Print dataframe\n",
    "snli_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a47891",
   "metadata": {},
   "source": [
    "Not bad, right? We can go further, and inspect the training & evaluation performance on SNLI using the interactive tensorboard extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2be0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45197), started 7:51:12 ago. (Use '!kill 45197' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-919c2e95c2aaaa07\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-919c2e95c2aaaa07\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=tb_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e0aa6",
   "metadata": {},
   "source": [
    "### Performance on SentEval\n",
    "\n",
    "Pickled results of the evaluation of all models on SentEval are provided in the `senteval` folder. If you want to re-evaluate on senteval, uncomment the cell below (and replace the checkpoint with your checkpoints of choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9b4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -W ignore eval.py --checkpoint pretrained/AWE/version_0/AWE-epoch=0.ckpt\n",
    "# !python -W ignore eval.py --checkpoint pretrained/LSTM/version_0/LSTM-epoch=0.ckpt\n",
    "# !python -W ignore eval.py --checkpoint pretrained/BiLSTM/version_0/BiLSTM-epoch=0.ckpt\n",
    "# !python -W ignore eval.py --checkpoint pretrained/BiLSTM-MaxPool/version_0/BiLSTM-MaxPool-epoch=0.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb0921",
   "metadata": {},
   "source": [
    "Let's see the test accuracies our models achieved on SentEval. This table is directly comparable to Table 4 of the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d09ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MR</th>\n",
       "      <th>CR</th>\n",
       "      <th>SUBJ</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>SST2</th>\n",
       "      <th>TREC</th>\n",
       "      <th>MRPC</th>\n",
       "      <th>SICK-R</th>\n",
       "      <th>SICK-E</th>\n",
       "      <th>STS14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWE</th>\n",
       "      <td>75.16</td>\n",
       "      <td>79.31</td>\n",
       "      <td>90.63</td>\n",
       "      <td>84.66</td>\n",
       "      <td>77.76</td>\n",
       "      <td>80.6</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.8</td>\n",
       "      <td>78.57</td>\n",
       "      <td>0.47 / 0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>71.54</td>\n",
       "      <td>77.03</td>\n",
       "      <td>86.55</td>\n",
       "      <td>85.06</td>\n",
       "      <td>74.96</td>\n",
       "      <td>78.2</td>\n",
       "      <td>71.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>84.45</td>\n",
       "      <td>0.56 / 0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM</th>\n",
       "      <td>72.89</td>\n",
       "      <td>79.15</td>\n",
       "      <td>89.61</td>\n",
       "      <td>85.13</td>\n",
       "      <td>76.94</td>\n",
       "      <td>86.2</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>84.72</td>\n",
       "      <td>0.55 / 0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM-MaxPool</th>\n",
       "      <td>75.29</td>\n",
       "      <td>81.88</td>\n",
       "      <td>91.17</td>\n",
       "      <td>85.92</td>\n",
       "      <td>78.91</td>\n",
       "      <td>88.2</td>\n",
       "      <td>73.68</td>\n",
       "      <td>0.88</td>\n",
       "      <td>85.69</td>\n",
       "      <td>0.58 / 0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MR     CR   SUBJ   MPQA   SST2  TREC   MRPC SICK-R SICK-E  \\\n",
       "AWE             75.16  79.31  90.63  84.66  77.76  80.6  71.36    0.8  78.57   \n",
       "LSTM            71.54  77.03  86.55  85.06  74.96  78.2  71.88   0.86  84.45   \n",
       "BiLSTM          72.89  79.15  89.61  85.13  76.94  86.2  71.36   0.86  84.72   \n",
       "BiLSTM-MaxPool  75.29  81.88  91.17  85.92  78.91  88.2  73.68   0.88  85.69   \n",
       "\n",
       "                      STS14  \n",
       "AWE             0.47 / 0.50  \n",
       "LSTM            0.56 / 0.54  \n",
       "BiLSTM          0.55 / 0.52  \n",
       "BiLSTM-MaxPool  0.58 / 0.56  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senteval_results = defaultdict(dict)\n",
    "\n",
    "# Iterate over all encoders\n",
    "for encoder in ['AWE', 'LSTM', 'BiLSTM', 'BiLSTM-MaxPool']:\n",
    "    results = pickle.load(open(f'senteval/{encoder}.pkl', 'rb'))\n",
    "    \n",
    "    # Iterate over all datasets\n",
    "    for dataset in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC', 'SICKRelatedness', 'SICKEntailment', 'STS14']:\n",
    "        if dataset == 'SICKRelatedness':\n",
    "            senteval_results[encoder][dataset] = results[dataset]['pearson']\n",
    "        elif dataset == 'STS14':\n",
    "            senteval_results[encoder][dataset] = '{:.2f} / {:.2f}'.format(\n",
    "                results['STS14']['all']['pearson']['wmean'],\n",
    "                results['STS14']['all']['spearman']['wmean']\n",
    "            )\n",
    "        else:\n",
    "            senteval_results[encoder][dataset] = results[dataset]['acc']\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "senteval_results = pd.DataFrame(senteval_results).T\n",
    "senteval_results = senteval_results.rename(columns={'SICKRelatedness': 'SICK-R', 'SICKEntailment': 'SICK-E'})\n",
    "\n",
    "# Print dataframe\n",
    "senteval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762a6e0",
   "metadata": {},
   "source": [
    "### Transfer Performance\n",
    "\n",
    "To measure the transfer performance, we replicate Table 3 from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06325a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNLI Val Acc</th>\n",
       "      <th>SNLI Test Acc</th>\n",
       "      <th>micro</th>\n",
       "      <th>macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWE</th>\n",
       "      <td>65.57</td>\n",
       "      <td>65.73</td>\n",
       "      <td>80.76</td>\n",
       "      <td>79.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>80.40</td>\n",
       "      <td>80.22</td>\n",
       "      <td>78.21</td>\n",
       "      <td>77.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM</th>\n",
       "      <td>79.38</td>\n",
       "      <td>79.44</td>\n",
       "      <td>80.80</td>\n",
       "      <td>80.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM-MaxPool</th>\n",
       "      <td>83.61</td>\n",
       "      <td>80.56</td>\n",
       "      <td>82.40</td>\n",
       "      <td>81.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SNLI Val Acc  SNLI Test Acc  micro  macro\n",
       "AWE                    65.57          65.73  80.76  79.11\n",
       "LSTM                   80.40          80.22  78.21  77.56\n",
       "BiLSTM                 79.38          79.44  80.80  80.16\n",
       "BiLSTM-MaxPool         83.61          80.56  82.40  81.65"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_results = defaultdict(dict)\n",
    "\n",
    "# Iterate over all encoders\n",
    "for encoder in ['AWE', 'LSTM', 'BiLSTM', 'BiLSTM-MaxPool']:\n",
    "    results = pickle.load(open(f'senteval/{encoder}.pkl', 'rb'))\n",
    "    \n",
    "    accuracies = [\n",
    "        results[dataset]['devacc'] for dataset in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC', 'SICKEntailment']\n",
    "    ]\n",
    "    \n",
    "    examples = [\n",
    "        results[dataset]['ndev'] for dataset in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC', 'SICKEntailment']\n",
    "    ]\n",
    "\n",
    "    transfer_results[encoder]['micro'] = np.average(accuracies, weights=examples)    \n",
    "    transfer_results[encoder]['macro'] = np.average(accuracies)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "transfer_results = pd.DataFrame(transfer_results).T\n",
    "\n",
    "# Print dataframe concatenated with the SNLI results\n",
    "pd.concat([snli_results, transfer_results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82390782",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b197a7",
   "metadata": {},
   "source": [
    "### Loading pre-trained models and evaluating on custom sentences\n",
    "\n",
    "The pretrained models are all instances of the `NLI` class, which has the following methods implemented:\n",
    "- `encode(self, sentence: str)`: which encodes a sentence into a dense vector representation\n",
    "- `classify(self, sentence_A: str, sentence_B: str):` which classifies a pair of sentences (`sentence_A`, `sentence_B`) as _entailement_, _contradiction_ or _neutral_\n",
    "\n",
    "For example, we can load a pretrained model as shown below, and see the 2048-dimensional encoding of our BiLSTM model with MaxPooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650c5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toliz/opt/miniconda3/envs/atcs/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'vocab' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['vocab'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1061, -0.0645, -0.0265,  ..., -0.1058, -0.0288, -0.0211])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_paths = {\n",
    "    'AWE': 'pretrained/AWE/version_0/AWE-epoch=6.ckpt',\n",
    "    'LSTM': 'pretrained/LSTM/version_0/LSTM-epoch=8.ckpt',\n",
    "    'BiLSTM': 'pretrained/BiLSTM/version_0/BiLSTM-epoch=4.ckpt',\n",
    "    'BiLSTM-MaxPool': 'pretrained/BiLSTM-MaxPool/version_0/BiLSTM-MaxPool-epoch=2.ckpt',\n",
    "}\n",
    "\n",
    "dm = SNLIDataModule(); dm.setup()\n",
    "model = NLI.load_from_checkpoint(checkpoint_paths['BiLSTM-MaxPool'], vocab=dm.vocab, data_dir='data/')\n",
    "\n",
    "model.encode('The cat is not the mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7fcf5",
   "metadata": {},
   "source": [
    "We can also use our model to classify our own sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e855ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim rides a bike to school every morning.    | Jim can ride a bike.                                   | entailment\n",
      "The restaurant opens at five o'clock         | The restaurant begins serving between four and nine.   | contradiction\n",
      "I liked the TV show.                         | It looks like it's gonna rain.                         | neutral\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    (\"Jim rides a bike to school every morning.\", \"Jim can ride a bike.\"),\n",
    "    (\"The restaurant opens at five o'clock\", \"The restaurant begins serving between four and nine.\"),\n",
    "    (\"I liked the TV show.\", \"It looks like it's gonna rain.\")\n",
    "]\n",
    "\n",
    "for sentence_A, sentence_B in pairs:\n",
    "    print(f'{sentence_A:45s}| {sentence_B:55s}| {model.classify(sentence_A, sentence_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bf564",
   "metadata": {},
   "source": [
    "The above samples seem very encouraging, but we can also spot some very obvious mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c183a5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like ice-cream.                            | It looks like it's gonna rain.                         | contradiction\n",
      "Butch is married to Barb.                    | Barb is not married to Butch.                          | neutral\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    (\"I like ice-cream.\", \"It looks like it's gonna rain.\"),\n",
    "    ('Butch is married to Barb.', 'Barb is not married to Butch.')\n",
    "]\n",
    "\n",
    "for sentence_A, sentence_B in pairs:\n",
    "    print(f'{sentence_A:45s}| {sentence_B:55s}| {model.classify(sentence_A, sentence_B)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dc26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
